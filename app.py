# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16S6mwq0HFI_-mSmt-BMRlD4SUsYrdXAg
"""



import streamlit as st
import joblib
import numpy as np
import re
from gensim.models import Word2Vec
from lime.lime_text import LimeTextExplainer


# ============================================================
# SAME CLEANING FUNCTION AS USED IN YOUR TRAINING SCRIPT
# ============================================================

def clean_text(text):
    text = text.lower()
    text = re.sub(r"[^a-zA-Z0-9\s]", "", text)
    return text


def sentence_vector(tokens, model, size=100):
    words = [model.wv[w] for w in tokens if w in model.wv]
    return np.mean(words, axis=0) if words else np.zeros(size)


# ============================================================
# LOAD EVERYTHING YOUR TRAINING SCRIPT GENERATED
# ============================================================

feature_type = open("best_feature_type.txt").read().strip()   # "tfidf" or "w2v"
model = joblib.load("best_spam_model.pkl")

if feature_type == "tfidf":
    vectorizer = joblib.load("tfidf_vectorizer.pkl")
else:
    w2v_model = Word2Vec.load("word2vec.model")


# ============================================================
# STREAMLIT UI
# ============================================================

st.set_page_config(page_title="SMS Spam Detector", page_icon="üì±", layout="centered")

st.title("üì± SMS Spam Detection Web App")
st.write("This model was trained using your ML project pipeline (TF-IDF + Word2Vec).")
st.write("Enter a message to classify it as **Spam** or **Ham**, along with an explanation.")

user_text = st.text_area("‚úâÔ∏è Enter your SMS message:", height=120)


# ============================================================
# LIME EXPLAINER ‚Äî Matches Your Pipeline
# ============================================================

explainer = LimeTextExplainer(class_names=["Ham", "Spam"])

def predict_proba_for_lime(texts):
    cleaned = [clean_text(t) for t in texts]

    # Use correct feature type
    if feature_type == "tfidf":
        X = vectorizer.transform(cleaned)
    else:
        X = np.array([sentence_vector(c.split(), w2v_model) for c in cleaned])

    # If model has predict_proba ‚Üí use it
    if hasattr(model, "predict_proba"):
        probs = model.predict_proba(X)

    # If model is SVM ‚Üí generate fake probability
    elif hasattr(model, "decision_function"):
        raw = model.decision_function(X)
        scaled = (raw - raw.min()) / (raw.max() - raw.min() + 1e-9)
        probs = np.vstack([1 - scaled, scaled]).T

    return probs


# ============================================================
# PREDICTION BUTTON
# ============================================================

if st.button("üîç Predict Spam / Ham"):

    if not user_text.strip():
        st.warning("Please type a message first.")
    else:
        cleaned = clean_text(user_text)
        tokens = cleaned.split()

        # Match your feature pipeline
        if feature_type == "tfidf":
            X = vectorizer.transform([cleaned])
        else:
            X = np.array([sentence_vector(tokens, w2v_model)])

        pred = model.predict(X)[0]

        label = "üö® SPAM" if pred == 1 else "‚úîÔ∏è HAM (Not Spam)"
        st.subheader("Prediction:")
        st.markdown(f"## {label}")

        # -------------------------
        # LIME EXPLANATION
        # -------------------------
        st.subheader("üîç Explanation (LIME)")

        explanation = explainer.explain_instance(
            user_text,
            predict_proba_for_lime,
            num_features=10
        )

        st.components.v1.html(explanation.as_html(), height=500, scrolling=True)


st.write("---")
st.write("Built with ‚ù§Ô∏è using your ML project models + Streamlit + LIME.")
